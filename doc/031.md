## 标题

友好的人工智能

## 脚本

```
友好的人工智能
是指
目标与我们
相一致的
人工智能
通用人工智能
带来的真正风险
并不是
它们的恶意
而是
它们的能力
一个超级智能
会非常善于
完成它的目标
如果它的目标
与我们人类的目标
不一致
那我们
就会有大麻烦
想要让
超级人工智能
与我们的目标
相一致
很重要
也很困难
这个问题
可以被划分为
三个子问题
一
让人工智能
学习
我们的目标
二
让人工智能
接受
我们的目标
三
让人工智能
保持
我们的目标
但这三个问题
我们一个
也没有解决
我们最好
从现在起
尽最大的努力
才是
最安全的选择
不要等到
超级智能
出现以后
才开始考虑
这些问题
到时候
亡羊补牢
为时已晚
```

草稿

```
通用人工智能带来的真正风险并不是它们的恶意，
而是它们的能力，一个超级智能会非常善于完成它的目标，
如果它的目标与我们人类的目标不一致，那我们就有麻烦了。

友好的人工智能是指目标与我们相一致的人工智能。
但是想要让超级人工智能与我们的目标相一致
很重要，也很困难。

让人工智能学习我们的目标；
让人工智能接受我们的目标；
让人工智能保持我们的目标。

要学习我们的目标，
人工智能需要搞明白的不是我们做了什么，
而是我们为什么这么做。

想要知道人们真正想要什么，
不能只听他们的一面之词。
你还需要这个世界的详细模型，
包括人们共有的许多偏好，
这些偏好我们通常不会明说。
一旦有了世界的模型，
我们就能通过观察人们的目标导向行为来搞明白他们想要什么，
即便他们并没有明说。
目前人工智能研究者正在努力让机器从行为中推断目标。

逆向增强学习希望人工智能体通过观察许多人在
许多场景的行为，包括真实场景、电影和书籍，
最终构建起关于人类偏好的精确模型。

即使我们建造了一个能学习人类目标的人工智能，
但这并不意味着它一定会接受这些目标。
就如人们为了让自己的孩子接受他们的目标，
可谓无所不用其极。
```

